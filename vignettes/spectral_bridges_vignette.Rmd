---
title: "Spectral Bridges Clustering"
author: "Christophe Ambroise"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
description: |
  Principle and use of the algorithm
vignette: >
  %\VignetteIndexEntry{Spectral Bridges}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```





# Introductive example

## The iris dataset
The **Iris dataset** is a classic dataset used in machine learning and statistics. It contains measurements of iris flowers from three different species: Setosa, Versicolor, and Virginica. 

- **Features**:
    
  -   **Sepal length** (in cm)
  -   **Sepal width** (in cm)
  -   **Petal length** (in cm)
    -   **Petal width** (in cm)
-   **Number of samples**: 150 (50 samples for each species)
    
-   **Species**:
    -   Iris Setosa
    -   Iris Versicolor
    -   Iris Virginica

```{r setup}
library(spectralBridges)
library(factoextra)

X<-iris[,1:4]
True_classes<-iris$Species

res<-spectral_bridges(X,n_classes=3,n_cells=12)
fviz_cluster(res)             
knitr::kable(table(res$cluster,True_classes))
```


# Algorithm description 

The Spectral bridges algorithm builds upon the traditional k-means and spectral clustering frameworks by subdividing data into small Voronoï regions, which are subsequently assessed for their connectivity. Drawing inspiration from Support vector machine margin concept, a non-parametric clustering approach is proposed, building  an affinity margin between each pair of Voronoï regions. This approach is characterized by minimal hyperparameters and delineation of intricate, non-convex cluster structures.

The Spectral Bridges algorithm first identifies local clusters to define Voronoï regions, computes edges with affinity weights between these regions, and ultimately cuts edges between regions with low inter-region density to determine the final clusters


The Spectral Bridges Clustering algorithm involves the following steps:

1. **Vector Quantization**: 
    - Perform K-means clustering on the input data `X`.
    - Obtain cluster centers, labels, and sizes.

2. **Affinity Computation**:
    - Center the data points within each cluster.
    - Compute distances between cluster centers.
    - Calculate affinity between clusters based on distances and centered data points.

3. **Transformation**:
    - Optionally apply an exponential transformation to the affinity matrix.

4. **Spectral Clustering**:
    - Compute the normalized Laplacian matrix.
    - Perform eigendecomposition on the Laplacian matrix.
    - Determine the number of classes using the kneedle method.
    - Apply K-means clustering on the eigenvectors.

5. **Result**:
    - Assign labels to the original data points based on the clustering results.


## Step-by-Step Implementation

### 1. Vector Quantization

First, we perform K-means clustering on the input data `X`.

```{r}
# Load necessary libraries
library(ClusterR)
library(factoextra)

# Sample data
set.seed(123)
X <- iris[,1:4]
True_classes=iris$Species
# Perform K-means clustering
n_cells <- 12
kmeans_result <- KMeans_rcpp(X, clusters = n_cells, num_init = 3, max_iters = 30, initializer = 'kmeans++')

# Extract cluster centers, labels, and sizes
kmeans_centers <- as.matrix(kmeans_result$centroids)
kmeans_labels <- kmeans_result$clusters
kmeans_size <- kmeans_result$obs_per_cluster
```


### 2. Affinity Computation


```{r}
 # Centering of X
  n<-nrow(X)
  X.centered <- as.matrix(do.call(rbind, lapply(1:n, function(i) {
    X[i, ] - kmeans_centers[kmeans_labels[i], ]
  })))

  # Pre-computation of distances between centers
  dist_centers <- as.matrix(dist(kmeans_centers))

  # Affinity
  affinity<-matrix(0,n_cells,n_cells)
  for (l in 1:(n_cells-1))
    for (k in (l+1):n_cells){
      distkl2 <- dist_centers[k, l]^2
      centered_k <- X.centered[kmeans_labels == k, ]
      centered_l <- X.centered[kmeans_labels == l, ]
      alpha_kl <- pmax(0, (kmeans_centers[l, ] - kmeans_centers[k, ]) %*% t(centered_k)) / distkl2
      alpha_lk <- pmax(0, (kmeans_centers[k, ] - kmeans_centers[l, ]) %*% t(centered_l)) / distkl2
      alphai <- c(alpha_kl, alpha_lk)
      affinity[l,k] <- sqrt(sum(alphai^2) / (kmeans_size[k] + kmeans_size[l]))
      affinity[k,l] <- affinity[l,k]
    }

```


### 3. Transformation

```{r}
transform <- "exp"
M <- 1e3

if (transform == "exp") {
  gamma <- log(M) / diff(quantile(affinity, c(0.1, 0.9)))
  affinity <- exp(gamma * (affinity - 0.5 * max(affinity)))
}
```

### 4. Spectral Clustering

Perform spectral clustering using the affinity matrix.


```{r}
# Normalized Laplacian matrix
D_inv_sqrt <- 1 / sqrt(rowSums(affinity))
L <- diag(n_cells) - t(affinity * D_inv_sqrt) * D_inv_sqrt
eigen.res <- eigen(-L, symmetric = TRUE)

# Determine the number of classes using the kneedle method
library(kneedle)
n_classes<-3
if (is.null(n_classes)) {
  n_classes <- kneedle(x = 1:length(eigen.res$values), y = eigen.res$values)[1] - 1
}
plot(eigen.res$values)
eigvecs <- eigen.res$vectors[, 1:n_classes]
eigvecs <- eigvecs / sqrt(rowSums(eigvecs ^ 2))
labels <- kmeans(eigvecs, nstart = 20, centers = n_classes)$cluster
```


### 5. Result

Assign labels to the original data points.

```{r}
# Assign labels based on clustering results
clusters <- labels[kmeans_labels]

# Return result
result <- list(clustering = clusters, data = X, class = "partition")
knitr::kable(table(Est_classes=result$clustering,True_classes=iris$Species))
```


